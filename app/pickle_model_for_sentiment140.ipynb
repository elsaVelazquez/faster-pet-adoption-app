{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "' data is from http://help.sentiment140.com/for-students .  The Sentiment140 is used for brand management, polling, and planning a purchase. Sentiment140 is used to discover the sentiment of a brand or product or even a topic on the social media platform Twitter. Rather than working on keywords-based approach, which leverages high precision for lower recall, Sentiment140 works with classifiers built from machine learning algorithms. The Sentiment140 uses classification results for individual tweets along with the traditional surface that aggregated metrics. '"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "''' heavily borrowed from https://github.com/GalvanizeDataScience/lectures/blob/Denver/text-classification/frank-burkholder/naive_bayes_sklearn.ipynb'''\n",
    "''' data is from http://help.sentiment140.com/for-students .  The Sentiment140 is used for brand management, polling, and planning a purchase. Sentiment140 is used to discover the sentiment of a brand or product or even a topic on the social media platform Twitter. Rather than working on keywords-based approach, which leverages high precision for lower recall, Sentiment140 works with classifiers built from machine learning algorithms. The Sentiment140 uses classification results for individual tweets along with the traditional surface that aggregated metrics. '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0          0\n1          0\n2          0\n3          0\n4          0\n          ..\n1599995    1\n1599996    1\n1599997    1\n1599998    1\n1599999    1\nName: 0, Length: 1600000, dtype: int64\n"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('data/sentiment140.csv',header = None)\n",
    "\n",
    "# drop emtpy records\n",
    "df = df.dropna()\n",
    "\n",
    "df.drop([1,2,3,4], axis=1, inplace=True)\n",
    "# df.head()\n",
    "\n",
    "\n",
    "X = df[5] #data\n",
    "X.to_numpy()\n",
    "# print(X)\n",
    "\n",
    "y= df[0].replace(4, 1) #turn the 4 into a 1 to show positive sentiment\n",
    "y.to_numpy()\n",
    "print(y)\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1600000\n1600000\n"
    }
   ],
   "source": [
    "print(len(X)) #11541\n",
    "print(len(y)) #11541"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "new_stopwords = ['a']\n",
    "new_stopwords_list = stop_words.union(new_stopwords)\n",
    "\n",
    "count_vect = CountVectorizer(lowercase=True, tokenizer=None, stop_words = new_stopwords_list,  analyzer='word', max_df=1.0, min_df=1,  max_features=None) \n",
    "                             \n",
    "\n",
    "count_vect.fit(X)\n",
    "\n",
    "target_names = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n                ngram_range=(1, 1), preprocessor=None,\n                stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n                            'aren', \"aren't\", 'as', 'at', 'be', 'because',\n                            'been', 'before', 'being', 'below', 'between',\n                            'both', 'but', 'by', 'can', 'couldn', \"couldn't\", ...},\n                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                tokenizer=None, vocabulary=None)\n"
    }
   ],
   "source": [
    "print(count_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The type of X_counts is <class 'scipy.sparse.csr.csr_matrix'>.\nThe X matrix has 1600000 rows (documents) and 686637 columns (words).\n"
    }
   ],
   "source": [
    "\n",
    "X_counts = count_vect.transform(X)\n",
    "print(\"The type of X_counts is {0}.\".format(type(X_counts)))\n",
    "print(\"The X matrix has {0} rows (documents) and {1} columns (words).\".format(\n",
    "        X_counts.shape[0], X_counts.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer(use_idf=True)\n",
    "tfidf_transformer.fit(X_counts)\n",
    "X_tfidf = tfidf_transformer.transform(X_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y.values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1280000, 686637)\n(1280000,)\n"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(320000, 686637)\n(320000,)\n"
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "nb_model.fit(X_train, y_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature_words = count_vect.get_feature_names()\n",
    "# n = 20 #number of top words associated with the category that we wish to see\n",
    "# target_names[categories] = 1\n",
    "# for cat in range(len(categories)): #categories == ['negative', 'positive']\n",
    "#     # print(f\"\\nTarget: {cat}\")\n",
    "#     # print(f\"\\nname: \", target_names[cat])\n",
    "#     print(f\"\\nTarget: {cat}, name:\", target_names[cat])\n",
    "#     log_prob = nb_model.feature_log_prob_[cat]\n",
    "#     i_topn = np.argsort(log_prob)[::-1][:n]\n",
    "#     features_topn = [feature_words[i] for i in i_topn]\n",
    "#     print(f\"Top {n} tokens: \", features_topn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = nb_model.predict(X_test)\n",
    "# X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.764128125"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.72625202, 0.35755314, 0.5112429 , ..., 0.66616774, 0.27820323,\n       0.29880966])"
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "y_pred_proba = nb_model.predict_proba(X_test)[:,1]\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh=0.7\n",
    "y_pred = (y_pred_proba>=thresh).astype(int)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1, 0, 0, ..., 0, 0, 0])"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7783251231527093"
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle and save the model \n",
    "import pickle\n",
    "save_documents = open(\"pickled_algos/pickled_nb_sentiment140.pickle\",\"wb\")\n",
    "pickle.dump(nb_model, save_documents)\n",
    "save_documents.close()\n",
    "\n",
    "tfidf = tfidf_transformer\n",
    "save_documents = open(\"pickled_algos/tfidf_transformer_sentiment140.pickle\", \"wb\")\n",
    "pickle.dump(tfidf, save_documents)\n",
    "save_documents.close()\n",
    "\n",
    "count_vect = count_vect\n",
    "save_documents = open(\"pickled_algos/count_vect_sentiment140.pickle\", \"wb\")\n",
    "pickle.dump(count_vect, save_documents)\n",
    "save_documents.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Positive Sentiment'"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "def predict_one_twitter(input):\n",
    "    with open('pickled_algos/pickled_nb_sentiment140.pickle', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    with open('pickled_algos/tfidf_transformer_sentiment140.pickle', 'rb') as f:\n",
    "        tfidf = pickle.load(f)\n",
    "\n",
    "    with open('pickled_algos/count_vect_sentiment140.pickle', 'rb') as f:\n",
    "        cv = pickle.load(f)\n",
    "\n",
    "  \n",
    "    cv_transformed = cv.transform(string_pred) #counts how many words\n",
    "    tfidf_transformed = tfidf.transform(cv_transformed)  #tf == cv . \n",
    "    string_predicted = model.predict(tfidf_transformed) \n",
    "    res = str(string_predicted[0])\n",
    "    if res == '0':\n",
    "        res = ('Negative Sentiment')\n",
    "    else:\n",
    "        res = (\"Positive Sentiment\")\n",
    "    return res\n",
    "\n",
    "# string_pred = ['this girl is a foster pit and has none of her teeth']\n",
    "# string_pred = ['fill out an online form to find this male puppy a forever home']\n",
    "string_pred = ['this dog is great i love him']\n",
    "predict_one_twitter(string_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}